{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CURRAN_M4_regression_classification_4.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/taycurran/DS-Unit-2-Linear-Models/blob/master/CURRAN_M4_regression_classification_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "491Dtlp6zxtV",
        "colab_type": "text"
      },
      "source": [
        "Lambda School Data Science\n",
        "\n",
        "*Unit 2, Sprint 1, Module 4*\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7IXUfiQ2UKj6"
      },
      "source": [
        "# Logistic Regression\n",
        "\n",
        "\n",
        "## Assignment ðŸŒ¯\n",
        "\n",
        "You'll use a [**dataset of 400+ burrito reviews**](https://srcole.github.io/100burritos/). How accurately can you predict whether a burrito is rated 'Great'?\n",
        "\n",
        "> We have developed a 10-dimensional system for rating the burritos in San Diego. ... Generate models for what makes a burrito great and investigate correlations in its dimensions.\n",
        "\n",
        "- [X] Do train/validate/test split. Train on reviews from 2016 & earlier. Validate on 2017. Test on 2018 & later.\n",
        "- [X] Begin with baselines for classification.\n",
        "- [X] Use scikit-learn for logistic regression.\n",
        "- [X] Get your model's validation accuracy. (Multiple times if you try multiple iterations.)\n",
        "- [X] Get your model's test accuracy. (One time, at the end.)\n",
        "- [X] Commit your notebook to your fork of the GitHub repo.\n",
        "\n",
        "\n",
        "## Stretch Goals\n",
        "\n",
        "- [ ] Add your own stretch goal(s) !\n",
        "- [ ] Make exploratory visualizations.\n",
        "- [X] Do one-hot encoding.\n",
        "- [X] Do [feature scaling](https://scikit-learn.org/stable/modules/preprocessing.html).\n",
        "- [ ] Get and plot your coefficients.\n",
        "- [ ] Try [scikit-learn pipelines](https://scikit-learn.org/stable/modules/compose.html)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "o9eSnDYhUGD7",
        "colab": {}
      },
      "source": [
        "%%capture\n",
        "import sys\n",
        "\n",
        "# If you're on Colab:\n",
        "if 'google.colab' in sys.modules:\n",
        "    DATA_PATH = 'https://raw.githubusercontent.com/LambdaSchool/DS-Unit-2-Linear-Models/master/data/'\n",
        "    !pip install category_encoders==2.*\n",
        "\n",
        "# If you're working locally:\n",
        "else:\n",
        "    DATA_PATH = '../data/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z9p9ffzVzxtb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load data downloaded from https://srcole.github.io/100burritos/\n",
        "import pandas as pd\n",
        "df = pd.read_csv(DATA_PATH+'burritos/burritos.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J4XzM6qWzxtc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Derive binary classification target:\n",
        "# We define a 'Great' burrito as having an\n",
        "# overall rating of 4 or higher, on a 5 point scale.\n",
        "# Drop unrated burritos.\n",
        "df = df.dropna(subset=['overall'])\n",
        "df['Great'] = df['overall'] >= 4"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DhBaOsnczxte",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Clean/combine the Burrito categories\n",
        "df['Burrito'] = df['Burrito'].str.lower()\n",
        "\n",
        "california = df['Burrito'].str.contains('california')\n",
        "asada = df['Burrito'].str.contains('asada')\n",
        "surf = df['Burrito'].str.contains('surf')\n",
        "carnitas = df['Burrito'].str.contains('carnitas')\n",
        "\n",
        "df.loc[california, 'Burrito'] = 'California'\n",
        "df.loc[asada, 'Burrito'] = 'Asada'\n",
        "df.loc[surf, 'Burrito'] = 'Surf & Turf'\n",
        "df.loc[carnitas, 'Burrito'] = 'Carnitas'\n",
        "df.loc[~california & ~asada & ~surf & ~carnitas, 'Burrito'] = 'Other'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DMeBVkX0zxtg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Drop some high cardinality categoricals\n",
        "df = df.drop(columns=['Notes', 'Location', 'Reviewer', 'Address', 'URL', 'Neighborhood'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8dgWQRSAzxti",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Drop some columns to prevent \"leakage\"\n",
        "df = df.drop(columns=['Rec', 'overall'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vS7eDcfX-pYh",
        "colab_type": "text"
      },
      "source": [
        "## MY CODE STARTS HERE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1J7og2UN-r_u",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "d4287718-7d3c-4e2e-ab2e-99efa25869ca"
      },
      "source": [
        "# Convert Date Column to DateTime DatatType\n",
        "df['Date'] = pd.to_datetime(df['Date'], infer_datetime_format=True)\n",
        "df['Date'].head(2)"
      ],
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0   2016-01-18\n",
              "1   2016-01-24\n",
              "Name: Date, dtype: datetime64[ns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 151
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4BvUFF_YfHMX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "b2594fcc-51a1-482d-f4b4-69d7dc4c4569"
      },
      "source": [
        "# Establish Separation Conditions\n",
        "cond_train = df['Date'] < '2017-01-01'\n",
        "cond_validate = (df['Date'] >= '2017-01-01') & (df['Date'] < '2018-01-01')\n",
        "cond_test = df['Date'] >= '2018-01-01'\n",
        "\n",
        "# Execute Separation\n",
        "train = df[cond_train]\n",
        "validate = df[cond_validate]\n",
        "test = df[cond_test]\n",
        "\n",
        "print('Separated DF Shapes')\n",
        "print(f\"Train: {train.shape}\")\n",
        "print(f\"Validate: {validate.shape}\")\n",
        "print(f\"Test: {test.shape}\")"
      ],
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Separated DF Shapes\n",
            "Train: (298, 59)\n",
            "Validate: (85, 59)\n",
            "Test: (38, 59)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-zVOjVer7ozB",
        "colab_type": "text"
      },
      "source": [
        "## **Test Split**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oeV1Rjew_dEE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "b1f50843-bb83-4279-c7c3-960434a77e3b"
      },
      "source": [
        "# Establish Separation Conditions\n",
        "cond_test = df['Date'] >= '2018-01-01'\n",
        "\n",
        "# Execute Separation\n",
        "test = df[cond_test]\n",
        "\n",
        "print('Separated Test Shape')\n",
        "print(f\"Test: {test.shape}\")"
      ],
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Separated Test Shape\n",
            "Test: (38, 59)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XFj7SjpHb-6Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Change the DataFrame to EXCLUDE Test Data\n",
        "condN_test = ~cond_test\n",
        "df = df[condN_test]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yHMLgWYXQSdi",
        "colab_type": "text"
      },
      "source": [
        "### **Wrangling**\n",
        "#### I am performing data exploration on Train+Validation sets together excluding Test Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "42BN0KePRKaA",
        "colab_type": "text"
      },
      "source": [
        "Encode Categorical Variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0wYfFELUUGCZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Drop Columns with Less or No Data\n",
        "droppedCols = ['Mass (g)', 'Density (g/mL)', 'Queso', 'Ham', 'Lobster',\n",
        "               'Mushroom', 'Bacon', 'Sushi', 'Avocado', 'Corn', 'Zucchini']\n",
        "       \n",
        "df = df.drop(droppedCols, axis=1)\n",
        "test = test.drop(droppedCols, axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1TsXBDKdAiZS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "3ae0054b-9183-4704-ced5-1d4f30e71ae0"
      },
      "source": [
        "# Check to Ensure Changes to Columns are Consistent\n",
        "df.columns == test.columns"
      ],
      "execution_count": 156,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 156
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pnoBiFj9bLxI",
        "colab_type": "text"
      },
      "source": [
        "## **Train/Validate Split**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "01DijRPsbe4u",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "9d298a8d-b60c-439f-f91a-fe11c66ad0fa"
      },
      "source": [
        "# Establish Separation Conditions\n",
        "cond_train = df['Date'] < '2017-01-01'\n",
        "cond_validate = (df['Date'] >= '2017-01-01') & (df['Date'] < '2018-01-01')\n",
        "\n",
        "# Execute Separation\n",
        "train = df[cond_train]\n",
        "validate = df[cond_validate]\n",
        "\n",
        "print('Separated DF Shapes')\n",
        "print(f\"Train: {train.shape}\")\n",
        "print(f\"Validate: {validate.shape}\")"
      ],
      "execution_count": 157,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Separated DF Shapes\n",
            "Train: (298, 48)\n",
            "Validate: (85, 48)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J-4y_y_BF1fL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Drop Date Column\n",
        "train = train.drop(['Date'], axis=1)\n",
        "validate = validate.drop(['Date'], axis=1)\n",
        "test = test.drop(['Date'], axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v6jE13tpBM2k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Establish X and y Feature Names\n",
        "target = 'Great'\n",
        "features = train.columns.drop(target)\n",
        "\n",
        "# Establish X Matrices and y Vectors\n",
        "X_train = train[features]\n",
        "y_train = train[target]\n",
        "\n",
        "X_val = validate[features]\n",
        "y_val = validate[target]\n",
        "\n",
        "X_test = test[features]\n",
        "y_test = test[target]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wq3mqAkJIKdF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Useful Variables\n",
        "trainSize = len(y_train)\n",
        "valSize = len(y_val)\n",
        "testSize = len(y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SpH9QyYSCIHz",
        "colab_type": "text"
      },
      "source": [
        "### More Wrangling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RT93_0nlQSF6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import category_encoders as ce\n",
        "\n",
        "# Execute OneHotEncoder\n",
        "encoder = ce.OneHotEncoder(use_cat_names=True)\n",
        "X_train_encoded = encoder.fit_transform(X_train)\n",
        "X_val_encoded = encoder.transform(X_val)\n",
        "X_test_encoded = encoder.transform(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7lPpD0QkEHzZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Take Care of NaN Values\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "# Execute SimpleImputer\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "X_train_imputed = imputer.fit_transform(X_train_encoded)\n",
        "X_val_imputed = imputer.transform(X_val_encoded)\n",
        "X_test_imputed = imputer.transform(X_test_encoded)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "piVPFjHEGZFO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Normalize Data\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train_imputed)\n",
        "X_val_scaled = scaler.transform(X_val_imputed)\n",
        "X_test_scaled = scaler.transform(X_test_imputed)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xVuozPrf745b",
        "colab_type": "text"
      },
      "source": [
        "## **Begin with the Baseline**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ONE38atGF-6M",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 155
        },
        "outputId": "681325a9-f9ee-4a09-bf8d-8f5fe92336a4"
      },
      "source": [
        "# Around 41 Percent of Burritos Are Great\n",
        "percGreat = y_train.value_counts()[1]/trainSize\n",
        "print(f\"Length y_train: {trainSize}\")\n",
        "print(f\"Percent of Great Burr: {percGreat}\")\n",
        "print(\"Majority = False\")\n",
        "print(\"\\nValue Counts\")\n",
        "y_train.value_counts()"
      ],
      "execution_count": 164,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Length y_train: 298\n",
            "Percent of Great Burr: 0.40939597315436244\n",
            "Majority = False\n",
            "\n",
            "Value Counts\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False    176\n",
              "True     122\n",
              "Name: Great, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 164
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j_1_mBKXMQoJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "5a4fc8a4-aa08-4e50-ac17-1e14df50d451"
      },
      "source": [
        "# Make Baseline Prediction from Train Mode (Majority)\n",
        "basePredMode = pd.Series([False] * valSize)\n",
        "print(f\"Val Size: {valSize}\")\n",
        "print(\"basePredMode Value_Counts\")\n",
        "basePredMode.value_counts()"
      ],
      "execution_count": 165,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Val Size: 85\n",
            "basePredMode Value_Counts\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False    85\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 165
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SH7_tHx4Harz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "3666739f-8510-4ed8-afcb-8d8c29ee7ff9"
      },
      "source": [
        "# Make Baseline Prediction from Train Percentage\n",
        "GreatBase = int(round(percGreat*valSize)) * [True] \n",
        "nGreatBase = int(round((1-percGreat)*valSize)) * [False]\n",
        "basePredPerc = GreatBase + nGreatBase\n",
        "basePredPerc = pd.Series(basePredPerc)\n",
        "print(\"basePredPerc Value_Counts\")\n",
        "basePredPerc.value_counts()"
      ],
      "execution_count": 166,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "basePredPerc Value_Counts\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False    50\n",
              "True     35\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 166
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BVsdzPbTLqMe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "b52e5aa9-0dcb-40f9-f150-b016e048ea7e"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Evaluate Baseline Accuracy from Percentage Prediction\n",
        "basePercScore = accuracy_score(y_val, basePredPerc)\n",
        "\n",
        "# Evaluate Baseline Accuracy from Percentage Prediction\n",
        "baseModeScore = accuracy_score(y_val, basePredMode)\n",
        "\n",
        "print(\"Baseline Accuracy Scores\")\n",
        "basePercScore, baseModeScore"
      ],
      "execution_count": 167,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Baseline Accuracy Scores\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.5411764705882353, 0.5529411764705883)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 167
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IZQkvQOj8Bb8",
        "colab_type": "text"
      },
      "source": [
        "## **Logistic Regression**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WUAilfQyOA83",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "324323ab-6b1e-4293-832f-1ca015c500d2"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Instantiate the LogisticRegression Tool\n",
        "model = LogisticRegression()\n",
        "\n",
        "# Train the Model\n",
        "model.fit(X_train_scaled, y_train)"
      ],
      "execution_count": 168,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
              "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 168
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LIgXADh28BO8",
        "colab_type": "text"
      },
      "source": [
        "## **Validation Accuracy**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AeUYKS56HgBd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "0b6fd2a1-3d7b-4a59-e3e6-59361608abff"
      },
      "source": [
        "print(\"Validation Accuracy\", model.score(X_val_scaled, y_val))"
      ],
      "execution_count": 169,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Validation Accuracy 0.7647058823529411\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M5yHnmYP8A-a",
        "colab_type": "text"
      },
      "source": [
        "## **Test Accuracy**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jbcfWATeCPlZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "741974c3-7698-4994-d0bd-35afeaab2e99"
      },
      "source": [
        "print(\"Test Accuracy\", model.score(X_test_scaled, y_test))"
      ],
      "execution_count": 170,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Accuracy 0.7631578947368421\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4JN05FfkJ_pP",
        "colab_type": "text"
      },
      "source": [
        "## **Conclusion**\n",
        "\n",
        "Validation Accuracy and Test Accuracy are Close in Value.\n",
        "This indicates that the model has low variance.\n",
        "The models accuracy is 50% higher than base estimates indicating the model has less bias than max bias."
      ]
    }
  ]
}